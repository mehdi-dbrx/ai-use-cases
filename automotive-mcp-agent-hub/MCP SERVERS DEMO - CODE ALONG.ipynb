{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f67936d5-e7c1-4bb6-8c66-a4d88c9dbfe2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83D\uDE80 Model Context Protocol (MCP) Servers Demo\n",
    "\n",
    "Welcome to the **MCP Servers Demo** for Databricks AI Engineers! \uD83C\uDFAF\n",
    "\n",
    "## \uD83D\uDCCB What is MCP?\n",
    "\n",
    "The **Model Context Protocol (MCP)** is an open standard that enables AI applications to securely connect to external data sources and tools. Think of it as a bridge between your AI models and the world of data they need to access.\n",
    "\n",
    "## \uD83C\uDFAF What You'll Learn\n",
    "\n",
    "In this demo, we'll demonstrate:\n",
    "- ⚙️ How to set up and connect to MCP servers\n",
    "- \uD83D\uDD27 Working with built-in Databricks MCP tools (like Python execution)\n",
    "- \uD83D\uDD0D Exploring custom MCP servers and tools\n",
    "- \uD83D\uDCCA Practical examples of tool invocation and response handling\n",
    "\n",
    "Let's dive in! \uD83C\uDFCA‍♂️\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d20a4c7-92d2-4573-9bda-70411e7407dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDD04 Setup: Enable Auto-reload\n",
    "\n",
    "First, let's enable auto-reload to ensure any changes to imported modules are automatically reflected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f15ab0c2-9eeb-449a-8fd0-4b397ec4d61b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98d3e6b3-5bea-42dc-8149-f9c98e05507c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDCE6 Installation: Required Dependencies\n",
    "\n",
    "Now we'll install all the necessary packages for working with MCP servers:\n",
    "- **`mcp`**: Core MCP protocol implementation\n",
    "- **`databricks-sdk`**: Databricks SDK with OpenAI integration\n",
    "- **`mlflow`**: For ML model lifecycle management\n",
    "- **`databricks-agents`**: Databricks AI agents framework\n",
    "- **`databricks-mcp`**: Databricks-specific MCP client\n",
    "\n",
    "⏳ This might take a few minutes to complete..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "30057f43-662d-438f-8300-973ee28667a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mcp>=1.9\n  Downloading mcp-1.13.0-py3-none-any.whl.metadata (68 kB)\nCollecting mlflow>=3.1.0\n  Downloading mlflow-3.2.0-py3-none-any.whl.metadata (29 kB)\nCollecting databricks-agents>=1.0.0\n  Downloading databricks_agents-1.3.0-py3-none-any.whl.metadata (3.5 kB)\nCollecting databricks-mcp\n  Downloading databricks_mcp-0.3.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: databricks-sdk[openai] in /databricks/python3/lib/python3.11/site-packages (0.40.0)\nCollecting databricks-sdk[openai]\n  Downloading databricks_sdk-0.63.0-py3-none-any.whl.metadata (39 kB)\nCollecting anyio>=4.5 (from mcp>=1.9)\n  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\nCollecting httpx-sse>=0.4 (from mcp>=1.9)\n  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting httpx>=0.27.1 (from mcp>=1.9)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting jsonschema>=4.20.0 (from mcp>=1.9)\n  Downloading jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\nCollecting pydantic-settings>=2.5.2 (from mcp>=1.9)\n  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\nCollecting pydantic<3.0.0,>=2.11.0 (from mcp>=1.9)\n  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\nCollecting python-multipart>=0.0.9 (from mcp>=1.9)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nCollecting sse-starlette>=1.6.1 (from mcp>=1.9)\n  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\nCollecting starlette>=0.27 (from mcp>=1.9)\n  Downloading starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\nCollecting uvicorn>=0.31.1 (from mcp>=1.9)\n  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: requests<3,>=2.28.1 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk[openai]) (2.31.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk[openai]) (2.35.0)\nCollecting openai (from databricks-sdk[openai])\n  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\nCollecting langchain-openai (from databricks-sdk[openai])\n  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\nCollecting mlflow-skinny==3.2.0 (from mlflow>=3.1.0)\n  Downloading mlflow_skinny-3.2.0-py3-none-any.whl.metadata (30 kB)\nCollecting mlflow-tracing==3.2.0 (from mlflow>=3.1.0)\n  Downloading mlflow_tracing-3.2.0-py3-none-any.whl.metadata (19 kB)\nCollecting Flask<4 (from mlflow>=3.1.0)\n  Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting alembic!=1.10.0,<2 (from mlflow>=3.1.0)\n  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\nCollecting docker<8,>=4.0.0 (from mlflow>=3.1.0)\n  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting graphene<4 (from mlflow>=3.1.0)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow>=3.1.0)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0) (3.7.2)\nRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0) (1.23.5)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0) (1.5.3)\nRequirement already satisfied: pyarrow<22,>=4.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0) (14.0.1)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0) (1.3.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0) (1.11.1)\nCollecting sqlalchemy<3,>=1.4.0 (from mlflow>=3.1.0)\n  Downloading sqlalchemy-2.0.43-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (5.5.0)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (8.0.4)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (3.0.0)\nCollecting fastapi<1 (from mlflow-skinny==3.2.0->mlflow>=3.1.0)\n  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (6.0.0)\nCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.2.0->mlflow>=3.1.0)\n  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.2.0->mlflow>=3.1.0)\n  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: packaging<26 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (23.2)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (5.29.3)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (6.0)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (0.5.1)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow>=3.1.0) (4.10.0)\nRequirement already satisfied: databricks-connect in /databricks/python3/lib/python3.11/site-packages (from databricks-agents>=1.0.0) (15.4.12)\nCollecting dataclasses-json (from databricks-agents>=1.0.0)\n  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\nCollecting jinja2>=3.0.0 (from databricks-agents>=1.0.0)\n  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\nCollecting tenacity>=8.5 (from databricks-agents>=1.0.0)\n  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\nCollecting tiktoken>=0.8.0 (from databricks-agents>=1.0.0)\n  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nCollecting tqdm (from databricks-agents>=1.0.0)\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\nCollecting urllib3>=2.0 (from databricks-agents>=1.0.0)\n  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting whenever==0.7.3 (from databricks-agents>=1.0.0)\n  Downloading whenever-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: boto3>1 in /databricks/python3/lib/python3.11/site-packages (from databricks-agents>=1.0.0) (1.34.39)\nRequirement already satisfied: botocore in /databricks/python3/lib/python3.11/site-packages (from databricks-agents>=1.0.0) (1.34.39)\nCollecting databricks-ai-bridge>=0.7.0 (from databricks-mcp)\n  Downloading databricks_ai_bridge-0.7.0-py3-none-any.whl.metadata (6.2 kB)\nCollecting Mako (from alembic!=1.10.0,<2->mlflow>=3.1.0)\n  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\nCollecting typing-extensions<5,>=4.0.0 (from mlflow-skinny==3.2.0->mlflow>=3.1.0)\n  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.11/site-packages (from anyio>=4.5->mcp>=1.9) (3.4)\nCollecting sniffio>=1.1 (from anyio>=4.5->mcp>=1.9)\n  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->databricks-agents>=1.0.0) (0.10.0)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->databricks-agents>=1.0.0) (0.10.3)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.11/site-packages (from botocore->databricks-agents>=1.0.0) (2.8.2)\nCollecting urllib3>=2.0 (from databricks-agents>=1.0.0)\n  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\nCollecting tabulate>=0.9.0 (from databricks-ai-bridge>=0.7.0->databricks-mcp)\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\nCollecting blinker>=1.9.0 (from Flask<4->mlflow>=3.1.0)\n  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting click<9,>=7.0 (from mlflow-skinny==3.2.0->mlflow>=3.1.0)\n  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting itsdangerous>=2.2.0 (from Flask<4->mlflow>=3.1.0)\n  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting markupsafe>=2.1.1 (from Flask<4->mlflow>=3.1.0)\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting werkzeug>=3.1.0 (from Flask<4->mlflow>=3.1.0)\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk[openai]) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk[openai]) (4.9)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=3.1.0)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=3.1.0)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.11/site-packages (from httpx>=0.27.1->mcp>=1.9) (2023.7.22)\nCollecting httpcore==1.* (from httpx>=0.27.1->mcp>=1.9)\n  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\nCollecting h11>=0.16 (from httpcore==1.*->httpx>=0.27.1->mcp>=1.9)\n  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\nCollecting attrs>=22.2.0 (from jsonschema>=4.20.0->mcp>=1.9)\n  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\nCollecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.20.0->mcp>=1.9)\n  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting referencing>=0.28.4 (from jsonschema>=4.20.0->mcp>=1.9)\n  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\nCollecting rpds-py>=0.7.1 (from jsonschema>=4.20.0->mcp>=1.9)\n  Downloading rpds_py-0.27.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0) (10.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0) (3.0.9)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<3->mlflow>=3.1.0) (2022.7)\nCollecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.11.0->mcp>=1.9)\n  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.11.0->mcp>=1.9)\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.11.0->mcp>=1.9)\n  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp>=1.9)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk[openai]) (2.0.4)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow>=3.1.0) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow>=3.1.0) (2.2.0)\nCollecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow>=3.1.0)\n  Downloading greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\nCollecting regex>=2022.1.18 (from tiktoken>=0.8.0->databricks-agents>=1.0.0)\n  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\nRequirement already satisfied: googleapis-common-protos>=1.56.4 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents>=1.0.0) (1.65.0)\nRequirement already satisfied: grpcio-status>=1.59.3 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents>=1.0.0) (1.69.0)\nRequirement already satisfied: grpcio>=1.59.3 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents>=1.0.0) (1.69.0)\nRequirement already satisfied: py4j==0.10.9.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents>=1.0.0) (0.10.9.7)\nRequirement already satisfied: setuptools>=68.0.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents>=1.0.0) (75.1.0)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from databricks-connect->databricks-agents>=1.0.0) (1.16.0)\nCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->databricks-agents>=1.0.0)\n  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json->databricks-agents>=1.0.0)\n  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting langchain-core<1.0.0,>=0.3.74 (from langchain-openai->databricks-sdk[openai])\n  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->databricks-sdk[openai]) (1.7.0)\nCollecting jiter<1,>=0.4.0 (from openai->databricks-sdk[openai])\n  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.2.0->mlflow>=3.1.0) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.2.0->mlflow>=3.1.0) (3.11.0)\nCollecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.74->langchain-openai->databricks-sdk[openai])\n  Downloading langsmith-0.4.14-py3-none-any.whl.metadata (14 kB)\nCollecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.74->langchain-openai->databricks-sdk[openai])\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.2.0->mlflow>=3.1.0)\n  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk[openai]) (0.4.8)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->databricks-agents>=1.0.0) (0.4.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.2.0->mlflow>=3.1.0) (5.0.1)\nCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain-openai->databricks-sdk[openai])\n  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\nCollecting orjson>=3.9.14 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai->databricks-sdk[openai])\n  Downloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\nCollecting requests-toolbelt>=1.0.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai->databricks-sdk[openai])\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: zstandard>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai->databricks-sdk[openai]) (0.23.0)\nDownloading mcp-1.13.0-py3-none-any.whl (160 kB)\nDownloading mlflow-3.2.0-py3-none-any.whl (25.8 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/25.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m25.7/25.8 MB\u001B[0m \u001B[31m146.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m25.8/25.8 MB\u001B[0m \u001B[31m69.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_skinny-3.2.0-py3-none-any.whl (2.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m72.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_tracing-3.2.0-py3-none-any.whl (1.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m93.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading databricks_agents-1.3.0-py3-none-any.whl (197 kB)\nDownloading whenever-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (418 kB)\nDownloading databricks_mcp-0.3.0-py3-none-any.whl (4.9 kB)\nDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\nDownloading anyio-4.10.0-py3-none-any.whl (107 kB)\nDownloading databricks_ai_bridge-0.7.0-py3-none-any.whl (18 kB)\nDownloading databricks_sdk-0.63.0-py3-none-any.whl (688 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/688.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m688.0/688.0 kB\u001B[0m \u001B[31m38.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\nDownloading flask-3.1.1-py3-none-any.whl (103 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\nDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\nDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\nDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\nDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\nDownloading jsonschema-4.25.0-py3-none-any.whl (89 kB)\nDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\nDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m93.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading sqlalchemy-2.0.43-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m168.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\nDownloading starlette-0.47.2-py3-none-any.whl (72 kB)\nDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\nDownloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m139.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading urllib3-2.0.7-py3-none-any.whl (124 kB)\nDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\nDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nDownloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\nDownloading openai-1.99.9-py3-none-any.whl (786 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/786.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m786.8/786.8 kB\u001B[0m \u001B[31m61.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\nDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\nDownloading click-8.2.1-py3-none-any.whl (102 kB)\nDownloading fastapi-0.116.1-py3-none-any.whl (95 kB)\nDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\nDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (587 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/587.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m587.7/587.7 kB\u001B[0m \u001B[31m54.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\nDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nDownloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\nDownloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\nDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\nDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\nDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\nDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\nDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\nDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\nDownloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/798.9 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m798.9/798.9 kB\u001B[0m \u001B[31m56.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading rpds_py-0.27.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\nDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nDownloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\nDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\nDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\nDownloading mako-1.3.10-py3-none-any.whl (78 kB)\nDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading langsmith-0.4.14-py3-none-any.whl (373 kB)\nDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nDownloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\nDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\nInstalling collected packages: whenever, urllib3, typing-extensions, tqdm, tenacity, tabulate, sniffio, rpds-py, regex, python-multipart, python-dotenv, orjson, marshmallow, markupsafe, jsonpointer, jiter, itsdangerous, httpx-sse, h11, gunicorn, greenlet, graphql-core, click, blinker, attrs, annotated-types, werkzeug, uvicorn, typing-inspection, typing-inspect, sqlalchemy, referencing, pydantic-core, opentelemetry-api, Mako, jsonpatch, jinja2, httpcore, graphql-relay, anyio, tiktoken, starlette, sse-starlette, requests-toolbelt, pydantic, opentelemetry-semantic-conventions, jsonschema-specifications, httpx, graphene, Flask, docker, dataclasses-json, databricks-sdk, alembic, pydantic-settings, opentelemetry-sdk, openai, langsmith, jsonschema, fastapi, mlflow-tracing, mlflow-skinny, mcp, langchain-core, mlflow, langchain-openai, databricks-ai-bridge, databricks-mcp, databricks-agents\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.16\n    Not uninstalling urllib3 at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1a9bc3d8-5e0f-4557-85e9-2b552e38496d\n    Can't uninstall 'urllib3'. No files were found to uninstall.\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.10.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1a9bc3d8-5e0f-4557-85e9-2b552e38496d\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 8.2.2\n    Not uninstalling tenacity at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1a9bc3d8-5e0f-4557-85e9-2b552e38496d\n    Can't uninstall 'tenacity'. No files were found to uninstall.\n  Attempting uninstall: click\n    Found existing installation: click 8.0.4\n    Not uninstalling click at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1a9bc3d8-5e0f-4557-85e9-2b552e38496d\n    Can't uninstall 'click'. No files were found to uninstall.\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.4\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1a9bc3d8-5e0f-4557-85e9-2b552e38496d\n    Can't uninstall 'blinker'. No files were found to uninstall.\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.6\n    Not uninstalling pydantic at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1a9bc3d8-5e0f-4557-85e9-2b552e38496d\n    Can't uninstall 'pydantic'. No files were found to uninstall.\n  Attempting uninstall: databricks-sdk\n    Found existing installation: databricks-sdk 0.40.0\n    Not uninstalling databricks-sdk at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1a9bc3d8-5e0f-4557-85e9-2b552e38496d\n    Can't uninstall 'databricks-sdk'. No files were found to uninstall.\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 2.11.4\n    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1a9bc3d8-5e0f-4557-85e9-2b552e38496d\n    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\nSuccessfully installed Flask-3.1.1 Mako-1.3.10 alembic-1.16.4 annotated-types-0.7.0 anyio-4.10.0 attrs-25.3.0 blinker-1.9.0 click-8.2.1 databricks-agents-1.3.0 databricks-ai-bridge-0.7.0 databricks-mcp-0.3.0 databricks-sdk-0.63.0 dataclasses-json-0.6.7 docker-7.1.0 fastapi-0.116.1 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.4 gunicorn-23.0.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.1 itsdangerous-2.2.0 jinja2-3.1.6 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 langchain-core-0.3.74 langchain-openai-0.3.30 langsmith-0.4.14 markupsafe-3.0.2 marshmallow-3.26.1 mcp-1.13.0 mlflow-3.2.0 mlflow-skinny-3.2.0 mlflow-tracing-3.2.0 openai-1.99.9 opentelemetry-api-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 orjson-3.11.2 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 python-multipart-0.0.20 referencing-0.36.2 regex-2025.7.34 requests-toolbelt-1.0.0 rpds-py-0.27.0 sniffio-1.3.1 sqlalchemy-2.0.43 sse-starlette-3.0.2 starlette-0.47.2 tabulate-0.9.0 tenacity-9.1.2 tiktoken-0.11.0 tqdm-4.67.1 typing-extensions-4.14.1 typing-inspect-0.9.0 typing-inspection-0.4.1 urllib3-2.0.7 uvicorn-0.35.0 werkzeug-3.1.3 whenever-0.7.3\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install -U \"mcp>=1.9\" \"databricks-sdk[openai]\" \"mlflow>=3.1.0\" \"databricks-agents>=1.0.0\" \"databricks-mcp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10245e48-e2ed-4d36-a929-9323c88d4eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDD04 Restart Python Environment\n",
    "\n",
    "After installing new packages, we need to restart the Python environment to ensure all dependencies are properly loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "966a321d-82cc-4f46-999f-312772802e89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1e570e1-c589-4fec-adaf-fbab4562ff0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83C\uDF10 Configure Workspace Connection\n",
    "\n",
    "Let's establish a connection to your Databricks workspace and construct the MCP server URL. This URL will be used to access the built-in AI tools provided by Databricks.\n",
    "\n",
    "The `system.ai` schema contains powerful tools like the Python code interpreter! \uD83D\uDC0D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14544ab2-ee17-4862-a4f4-3c4ba342faf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://adb-984752964297111.11.azuredatabricks.net/api/2.0/mcp/functions/system/ai'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "workspace_client = WorkspaceClient()\n",
    "workspace_hostname = workspace_client.config.host\n",
    "mcp_server_url = f\"{workspace_hostname}/api/2.0/mcp/functions/system/ai\"\n",
    "mcp_server_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a0b51da-8f98-4b7d-beba-65451ff5670b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDEE0️ Helper Functions: MCP Client Operations\n",
    "\n",
    "Here we define utility functions to:\n",
    "- **Connect** to MCP servers and discover available tools \uD83D\uDD0D\n",
    "- **Invoke** MCP tools with parameters and handle responses \uD83D\uDCE1\n",
    "\n",
    "These functions will be reused throughout the demo to interact with different MCP servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3158ffd0-26ed-41a4-b9be-6789eac22d8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_mcp import DatabricksMCPClient\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# This snippet below uses the Unity Catalog functions MCP server to expose built-in\n",
    "# AI tools under `system.ai`, like the `system.ai.python_exec` code interpreter tool\n",
    "def test_connect_to_server_get_tools(mcp_server_url):\n",
    "     mcp_client = DatabricksMCPClient(server_url=mcp_server_url, workspace_client=workspace_client)\n",
    "     tools = mcp_client.list_tools()\n",
    "\n",
    "     print(\n",
    "         f\"Discovered tools {[t.name for t in tools]} \"\n",
    "         f\"from MCP server {mcp_server_url}\"\n",
    "     )\n",
    "     return mcp_client, tools\n",
    "\n",
    "def mcp_invoke_tool(mcp_client, tool, params):\n",
    "     import json\n",
    "     result = mcp_client.call_tool(\n",
    "         tool, params\n",
    "     )\n",
    "     print(f\"Called MCP tool {tool}\")\n",
    "     print(f\"Response:\\n \")\n",
    "     [print(json.dumps(item, indent=2, ensure_ascii=False)) for item in json.loads(json.loads(result.content[0].text)['rows'][0][0])]\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b20545b3-f77c-4dc5-a1ef-3914787defc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDD0D Discover Built-in AI Tools\n",
    "\n",
    "Let's connect to the Databricks system AI MCP server and see what tools are available! \n",
    "\n",
    "Expected tools:\n",
    "- **`system__ai__python_exec`**: A powerful Python code interpreter that can execute code in a sandboxed environment \uD83D\uDC0D✨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf6d6847-320c-4a85-abb3-ff605d995600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "## \uD83D\uDCCA Inspect Tool Schema\n",
    "\n",
    "Let's examine the detailed schema of the Python execution tool. This will show us:\n",
    "- \uD83D\uDCDD **Description**: What the tool does\n",
    "- \uD83D\uDD27 **Input Schema**: What parameters it expects\n",
    "- \uD83D\uDCE4 **Output Schema**: What it returns\n",
    "- ⚙️ **Annotations**: Additional metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8281459-ec8c-4e0c-b7ad-904b6a8d2910",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered tools ['system__ai__python_exec'] from MCP server https://adb-984752964297111.11.azuredatabricks.net/api/2.0/mcp/functions/system/ai\n"
     ]
    }
   ],
   "source": [
    "mcp_client, tools = test_connect_to_server_get_tools(mcp_server_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd63374-292b-4f58-ae4d-3c06e5544a58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n  \"name\": \"system__ai__python_exec\",\n  \"title\": null,\n  \"description\": \"Executes Python code in a stateless sandboxed environment and returns its stdout. The runtime cannot access files or read previous executions' output. All operations must be self-contained, using only standard Python libraries. Calls to other tools are prohibited.\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"required\": [\n      \"code\"\n    ],\n    \"properties\": {\n      \"code\": {\n        \"type\": \"string\",\n        \"description\": \"Python code to execute. Ensure that all variables are initialized within the code, and import any necessary standard libraries. The code must print the final result to stdout. Do not attempt to access files or external systems.\"\n      }\n    }\n  },\n  \"outputSchema\": null,\n  \"annotations\": \"title=None readOnlyHint=None destructiveHint=None idempotentHint=None openWorldHint=None catalog='system' schema='ai' language='Python' routine_body='EXTERNAL'\",\n  \"meta\": null\n}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(tools[0].__dict__, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8dc2d53-b150-4750-b1c8-aaca6a917f13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDE80 Test Python Code Execution\n",
    "\n",
    "Time for our first tool invocation! Let's test the Python executor with a simple \"Hello, world!\" example.\n",
    "\n",
    "**What happens here:**\n",
    "1. We send Python code to the MCP server\n",
    "2. The server executes it in a secure sandbox\n",
    "3. We receive the output back as structured data\n",
    "\n",
    "\uD83D\uDD12 **Security Note**: The execution happens in a stateless, sandboxed environment for safety!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0062ab4b-0b76-46f6-979b-1189eac41bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called system__ai__python_exec tool and got result:\n \n{\n  \"is_truncated\": false,\n  \"columns\": [\n    \"output\"\n  ],\n  \"rows\": [\n    [\n      \"Hello, world!\\n\"\n    ]\n  ]\n}\n"
     ]
    }
   ],
   "source": [
    "mcp_invoke_tool(mcp_client,tools[0].name, {\"code\": \"print('Hello, world!')\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6a309a4-7e4a-4a88-9df1-cfa92d665d99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDD04 Connect to Custom MCP Server\n",
    "\n",
    "Now let's explore a **custom MCP server**! This one provides insurance-related tools:\n",
    "\n",
    "**Server**: `mc/fidel` - Fidelidade Insurance Company tools  \n",
    "**Expected Tool**: `mc__fidel__search_conditions` - Search insurance policy conditions \uD83D\uDCCB\uD83D\uDD0D\n",
    "\n",
    "This demonstrates how MCP can be used to expose domain-specific business tools!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a3149ce-4d8f-445d-af95-3fa092c1f039",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered tools ['mc__fidel__search_conditions'] from MCP server https://adb-984752964297111.11.azuredatabricks.net/api/2.0/mcp/functions/mc/fidel\n"
     ]
    }
   ],
   "source": [
    "mcp_server_url = f\"{workspace_hostname}/api/2.0/mcp/functions/mc/fidel\"\n",
    "mcp_client, tools = test_connect_to_server_get_tools(mcp_server_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "954a50e0-3868-4f5e-bea5-65698190ca6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDCCB Examine Insurance Tool Schema\n",
    "\n",
    "Let's inspect the insurance search tool to understand:\n",
    "- \uD83C\uDFAF **Purpose**: What this business tool accomplishes\n",
    "- \uD83D\uDCE5 **Input**: How to query insurance conditions\n",
    "- \uD83D\uDCCA **Output**: What kind of insurance data it returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b4265c6-0455-4d5f-89d8-abaa64ab6375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n  \"name\": \"mc__fidel__search_conditions\",\n  \"title\": null,\n  \"description\": \"This tool is a string retrieval tool for querying the conditions of utilisation of Fidelidade Insurance Company\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"required\": [\n      \"my_query\"\n    ],\n    \"properties\": {\n      \"my_query\": {\n        \"type\": \"string\"\n      }\n    }\n  },\n  \"outputSchema\": null,\n  \"annotations\": \"title=None readOnlyHint=None destructiveHint=None idempotentHint=None openWorldHint=None catalog='mc' schema='fidel' language='SQL' routine_body='SQL'\",\n  \"meta\": null\n}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(tools[0].__dict__, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0414d7e-5050-4632-a924-e8e8aef41a01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDD0D Query Insurance Conditions\n",
    "\n",
    "Let's test the insurance search tool by querying for **hazard types** covered by insurance policies.\n",
    "\n",
    "**Query**: \"names of hazard types covered by my insurance\"\n",
    "\n",
    "This demonstrates how MCP can expose specialized business knowledge and make it accessible to AI systems! \uD83C\uDFE2\uD83D\uDCBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cffb420c-1942-4aff-97de-9ad29f2a5964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called MCP tool mc__fidel__search_conditions\nResponse:\n \n{\n  \"chapter_num\": \"III\",\n  \"chapter_title\": \"do Título II do Decreto-Lei n.º 291/2007, de 21 de agosto.\",\n  \"clause_num\": \"5\",\n  \"clause_titulo\": \"EXCLUSÕES DA GARANTIA\",\n  \"clause_content\": \"OBRIGATÓRIA\\n1.  Excluem-se da garantia obrigatória do seguro \\nos danos corporais sofridos pelo condutor do \\nveículo seguro responsável pelo acidente, as- \\nsim como os danos decorrentes daqueles.\\n05/92\\nmarço 2024 - AU0522.  Excluem-se igualmente da garantia obrigatória \\ndo seguro quaisquer danos materiais causados \\nàs seguintes pessoas:\\n a)  Condutor do veículo responsável pelo \\nacidente;\\n b) Tomador do Seguro;\\n c)  Todos aqueles cuja responsabilidade é, nos \\ntermos legais, garantida, nomeadamente \\nem consequência da compropriedade do \\nveículo seguro;\\n d)  Sociedades ou representantes legais das \\npessoas coletivas responsáveis pelo aciden- \\nte, quando no exercício das suas funções;\\n e)  Cônjuge, ascendentes, descendentes ou \\nadotados das pessoas referidas nas alíneas \\na) a c), assim como outros parentes ou afins \\naté ao 3.º grau das mesmas pessoas, mas, \\nneste último caso, só quando elas coabitem \\nou vivam a seu cargo;\\n f)  Aqueles que, nos termos dos Artigos 495.º, \\n496.º e 499.º do Código Civil, beneficiem \\nde uma pretensão indemnizatória decor- \\nrente de vínculos com alguma das pessoas \\nreferidas nas alíneas anteriores;\\n g)  A passageiros, quando transportados em \\ncontravenção às regras relativas ao trans- \\nporte de passageiros constantes do Código \\nda Estrada, onde designadamente relevam \\nos regimes especiais relativos ao trans- \\nporte de crianças, ao transporte fora dos \\nassentos e ao transporte em motociclos, \\ntriciclos, quadriciclos e ciclomotores.\\n3.  No caso de falecimento, em consequência do \\nacidente, de qualquer das pessoas referidas \\nnas alíneas e) e f) do número anterior, é excluí- \\nda qualquer indemnização ao responsável do \\nacidente.\\n4.  Excluem-se igualmente da garantia obrigatória \\ndo seguro:\\n a)  Os danos causados no próprio veículo \\nseguro;\\n b)  Os danos causados nos bens transporta- \\ndos no veículo seguro, quer se verifiquem \\ndurante o transporte quer em operações de \\ncarga e descarga;  c)  Quaisquer danos causados a terceiros em \\nconsequência de operações de carga e \\ndescarga;\\n d)  Os danos devidos, direta ou indiretamente, \\na explosão, libertação de calor ou radiação, \\nprovenientes de desintegração ou fusão de \\nátomos, aceleração artificial de partículas \\nou radioatividade;\\n e)  Quaisquer danos ocorridos durante provas \\ndesportivas e respetivos treinos oficiais, \\nsalvo tratando-se de seguro de provas \\ndesportivas, caso em que se aplicam as \\npresentes condições gerais com as devidas \\nadaptações previstas para o efeito pelas \\npartes.\\n5.  Nos casos de roubo, furto ou furto de uso de \\nveículos e acidentes de viação dolosamente \\nprovocados, o seguro não garante a satisfação \\ndas indemnizações devidas pelos respetivos \\nautores e cúmplices para com o proprietário, \\nusufrutuário, adquirente com reserva de pro- \\npriedade ou locatário em regime de locação \\nfinanceira, nem para com os autores ou cúmpli- \\nces ou para com os passageiros transportados \\nque tivessem conhecimento da posse ilegíti- \\nma do veículo e de livre vontade nele fossem \\ntransportados.\",\n  \"capitulo\": \"do Título II do Decreto-Lei n.º 291/2007, de 21 de agosto.\",\n  \"chunk_id\": \"3a0880431cb55523f0fe8075d6228bbb\",\n  \"search_score\": 0.0020573847\n}\n{\n  \"chapter_num\": \"III\",\n  \"chapter_title\": \"do Título\",\n  \"clause_num\": \"3\",\n  \"clause_titulo\": \"ÂMBITO DA GARANTIA\",\n  \"clause_content\": \"A presente Condição Especial garante ao Se-\\ngurado, nos termos constantes das Condições \\nParticulares, o ressarcimento dos danos causados \\nao veículo seguro por tempestades, inundações, \\nfenómenos sísmicos ou movimentos de terras, \\nbem como pela queda de árvores, de telhas, de \\nchaminés, de muros ou construções urbanas pro- \\nvocada pelos fenómenos referidos.\",\n  \"capitulo\": \"do Título\",\n  \"chunk_id\": \"cdbbeec37b1b1bf12ba1b887f152e40e\",\n  \"search_score\": 0.0020537507\n}\n{\n  \"chapter_num\": \"III\",\n  \"chapter_title\": \"do Título\",\n  \"clause_num\": \"2\",\n  \"clause_titulo\": \"ÂMBITO DA GARANTIA E CAPITAL\",\n  \"clause_content\": \"SEGURO\\n1.  A presente Condição Especial garante apenas \\na responsabilidade civil extracontratual por \\ndanos materiais e/ou corporais, causados in-\\nvoluntariamente a terceiros, pelo(s) veículo(s) \\nidentificado(s) nas Condições Particulares, \\ndurante a sua utilização numa operação de \\nlaboração.\\n2.  A garantia referida no número anterior apenas \\nfunciona no caso do acidente não ser enquadrá-\\nvel no seguro obrigatório de responsabilidade \\ncivil automóvel.\\n3.  No caso do acidente ser também um acidente \\nde trabalho, apenas se encontram abrangidos \\nos danos não cobertos pelo seguro de aciden-\\ntes de trabalho.\",\n  \"capitulo\": \"do Título\",\n  \"chunk_id\": \"c9387fa9257a8cf6912caccde8538aa8\",\n  \"search_score\": 0.0020361692\n}\n"
     ]
    }
   ],
   "source": [
    "mcp_invoke_tool(mcp_client,tools[0].name, {\"my_query\": \"names of hazard types covered by my insurance\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53575036-3623-421c-8b0e-81912a0bb8a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDD10 Authentication Setup\n",
    "\n",
    "For connecting to **external MCP servers** (like Databricks Apps), we need authentication. \n",
    "\n",
    "**\uD83D\uDEE0️ Setup Instructions:**\n",
    "1. Run this in your **local terminal**:\n",
    "   ```bash\n",
    "   databricks auth login --host https://adb-984752964297111.11.azuredatabricks.net\n",
    "   Databricks profile name: mehdi-dbx-profile\n",
    "   databricks auth token -p mehdi-dbx-profile\n",
    "   ```\n",
    "2. Copy the token and enter it when prompted below \uD83D\uDD11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09bf6d80-7fe2-4d55-a056-9502e13683a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your Databricks token:  [REDACTED]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "token = getpass.getpass(\"Enter your Databricks token: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0fd83cd-cdc1-4d78-a03b-bc411ef59700",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83C\uDF10 Connect to External MCP Server App\n",
    "\n",
    "Now we'll connect to a **Databricks App** that hosts a custom MCP server! This demonstrates:\n",
    "\n",
    "- \uD83D\uDD17 **External Connectivity**: How to connect to MCP servers outside Unity Catalog\n",
    "- \uD83D\uDEE1️ **OAuth Authentication**: Secure connection using Databricks OAuth\n",
    "- \uD83D\uDCF1 **App Integration**: How Databricks Apps can expose MCP tools\n",
    "\n",
    "**Target App**: `custom-mcp-server-mehdi` - A simple calculator service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8e24de9-a9c3-4211-9c19-561b54f0a7b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_mcp import DatabricksOAuthClientProvider\n",
    "from databricks.sdk.credentials_provider import ModelServingUserCredentials\n",
    "from mcp.client.streamable_http import streamablehttp_client as connect\n",
    "from mcp import ClientSession\n",
    "\n",
    "import logging\n",
    "logging.getLogger('mcp.client.streamable_http').setLevel(logging.ERROR)\n",
    "\n",
    "workspace_hostname = WorkspaceClient().config.host\n",
    "MCP_SERVER_DATABRICKS_APP_DOMAIN = 'custom-mcp-server-mehdi-984752964297111.11.azure.databricksapps.com'\n",
    "\n",
    "async def connect_to_custom_mcp_server_app_and_get_tools():\n",
    "    \n",
    "    app_url = f\"https://{MCP_SERVER_DATABRICKS_APP_DOMAIN}/mcp\"\n",
    "\n",
    "    client = WorkspaceClient(\n",
    "        host=workspace_hostname,\n",
    "        token= token  # Replace with your actual token\n",
    "    )\n",
    "\n",
    "    async with connect(app_url, auth=DatabricksOAuthClientProvider(client)) as (\n",
    "        read_stream,\n",
    "        write_stream,\n",
    "        _,\n",
    "    ):\n",
    "        async with ClientSession(read_stream, write_stream) as session:\n",
    "            await session.initialize()\n",
    "            tools = await session.list_tools()\n",
    "            print(f\"Available tools: {[tool.name for tool in tools.tools]}\")\n",
    "            return session, tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54133d98-e310-4d51-a6e9-ff2768ea1279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83E\uDDEE Test External MCP Server Tools\n",
    "\n",
    "Let's explore and test the tools from our external Databricks App MCP server!\n",
    "\n",
    "**Expected Tool**: `add` - A simple addition calculator\n",
    "\n",
    "This demonstrates the full MCP workflow with external servers. \uD83D\uDD04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9f9685e-f90a-43a1-96b3-447f17aa2bdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools: ['add']\n"
     ]
    }
   ],
   "source": [
    "tools = await with_mcp_session(explore_tools)\n",
    "result = await with_mcp_session(call_add_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7b2578d-1632-4ba5-97c5-02b5c3c65334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDCCA Detailed Tool Schema (JSON)\n",
    "\n",
    "Let's examine the complete JSON schema of our external tools for deeper understanding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e166d638-25d6-4caa-9836-9dde9b53127d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n  {\n    \"name\": \"add\",\n    \"title\": null,\n    \"description\": \"Add two numbers\",\n    \"inputSchema\": {\n      \"properties\": {\n        \"a\": {\n          \"title\": \"A\",\n          \"type\": \"integer\"\n        },\n        \"b\": {\n          \"title\": \"B\",\n          \"type\": \"integer\"\n        }\n      },\n      \"required\": [\n        \"a\",\n        \"b\"\n      ],\n      \"title\": \"addArguments\",\n      \"type\": \"object\"\n    },\n    \"outputSchema\": {\n      \"properties\": {\n        \"result\": {\n          \"title\": \"Result\",\n          \"type\": \"integer\"\n        }\n      },\n      \"required\": [\n        \"result\"\n      ],\n      \"title\": \"addOutput\",\n      \"type\": \"object\"\n    },\n    \"annotations\": null,\n    \"meta\": null\n  }\n]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps([tool.__dict__ for tool in tools.tools], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b130a234-006b-4d8d-b69d-777ef3d9ccaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDC0D Pretty Print Tool Schema\n",
    "\n",
    "For better readability, let's use Python's `pprint` to display the tool schema:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5506ee09-5743-41d9-9d11-c056f8b20bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'annotations': None,\n  'description': 'Add two numbers',\n  'inputSchema': {'properties': {'a': {'title': 'A', 'type': 'integer'},\n                                 'b': {'title': 'B', 'type': 'integer'}},\n                  'required': ['a', 'b'],\n                  'title': 'addArguments',\n                  'type': 'object'},\n  'meta': None,\n  'name': 'add',\n  'outputSchema': {'properties': {'result': {'title': 'Result',\n                                             'type': 'integer'}},\n                   'required': ['result'],\n                   'title': 'addOutput',\n                   'type': 'object'},\n  'title': None}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint([tool.__dict__ for tool in tools.tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1426b7e-82c2-41ac-9807-1487a461d184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83C\uDF33 Beautiful Tool Visualization\n",
    "\n",
    "Now let's create a beautiful tree visualization of our MCP tools using Rich! This provides:\n",
    "\n",
    "- \uD83C\uDFAF **Clear structure**: Tool names, descriptions, and parameters\n",
    "- \uD83C\uDFA8 **Color coding**: Different colors for different types of information\n",
    "- \uD83D\uDCCB **Hierarchical view**: Easy to understand tool capabilities at a glance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ab31adf-6fcc-438f-9750-8cb1d0517077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install rich -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52d5bb4e-6fc8-4e13-805e-e4a22b79a198",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tools\n",
       "└── <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">add</span>: Add two numbers\n",
       "    ├── <span style=\"color: #008000; text-decoration-color: #008000\">Input Parameters</span>\n",
       "    │   ├── a: integer - A\n",
       "    │   └── b: integer - B\n",
       "    └── <span style=\"color: #808000; text-decoration-color: #808000\">Output Parameters</span>\n",
       "        └── result: integer - Result\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tools\n",
       "└── \u001B[1;34madd\u001B[0m: Add two numbers\n",
       "    ├── \u001B[32mInput Parameters\u001B[0m\n",
       "    │   ├── a: integer - A\n",
       "    │   └── b: integer - B\n",
       "    └── \u001B[33mOutput Parameters\u001B[0m\n",
       "        └── result: integer - Result\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "from rich.tree import Tree\n",
    "\n",
    "tree = Tree(\"Tools\")\n",
    "for tool in tools.tools:\n",
    "   tool_tree = tree.add(f\"[bold blue]{tool.name}[/bold blue]: {tool.description}\")\n",
    "   \n",
    "   # Input parameters\n",
    "   input_tree = tool_tree.add(\"[green]Input Parameters[/green]\")\n",
    "   for param, details in tool.inputSchema.get('properties', {}).items():\n",
    "       input_tree.add(f\"{param}: {details.get('type', 'unknown')} - {details.get('title', '')}\")\n",
    "   \n",
    "   # Output parameters  \n",
    "   output_tree = tool_tree.add(\"[yellow]Output Parameters[/yellow]\")\n",
    "   for param, details in tool.outputSchema.get('properties', {}).items():\n",
    "       output_tree.add(f\"{param}: {details.get('type', 'unknown')} - {details.get('title', '')}\")\n",
    "\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acd9675f-3c93-4ec6-bb1a-93c071c22bb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \uD83D\uDCCB Final Result Analysis\n",
    "\n",
    "Let's examine the detailed response from our MCP tool call to understand the complete response structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ad98301-844e-48d7-991d-cdf7e9870789",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n  \"meta\": null,\n  \"content\": [\n    \"type='text' text='800' annotations=None meta=None\"\n  ],\n  \"structuredContent\": {\n    \"result\": 800\n  },\n  \"isError\": false\n}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result.__dict__, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4fcd15c-edf3-48bb-b645-bf9dad2a2df6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# \uD83C\uDF89 Demo Summary\n",
    "\n",
    "## \uD83C\uDFC6 What We Accomplished\n",
    "\n",
    "Congratulations! You've successfully explored the Model Context Protocol (MCP) ecosystem in Databricks! Here's what we covered:\n",
    "\n",
    "### \uD83D\uDD27 **Built-in Tools Explored**\n",
    "- ✅ **System AI Python Executor**: Executed Python code in a secure sandbox\n",
    "- ✅ **Tool Discovery**: Connected to Unity Catalog MCP servers\n",
    "- ✅ **Schema Inspection**: Examined tool input/output schemas\n",
    "\n",
    "### \uD83C\uDFE2 **Custom Business Tools**\n",
    "- ✅ **Insurance Search Tool**: Queried domain-specific business data\n",
    "- ✅ **Structured Responses**: Received formatted business intelligence\n",
    "- ✅ **Real-world Integration**: Demonstrated practical business use cases\n",
    "\n",
    "### \uD83C\uDF10 **External App Integration**\n",
    "- ✅ **Databricks Apps**: Connected to external MCP servers\n",
    "- ✅ **OAuth Authentication**: Secured connections with proper authentication\n",
    "- ✅ **Calculator Service**: Tested external tool functionality\n",
    "\n",
    "### \uD83C\uDFA8 **Advanced Visualization**\n",
    "- ✅ **Rich Formatting**: Created beautiful tool visualizations\n",
    "- ✅ **Tree Structures**: Organized tool information hierarchically\n",
    "- ✅ **Response Analysis**: Examined detailed tool responses\n",
    "\n",
    "## \uD83D\uDE80 **Key Takeaways**\n",
    "\n",
    "1. **\uD83D\uDD0C Seamless Integration**: MCP provides a standardized way to connect AI systems to external tools and data sources\n",
    "\n",
    "2. **\uD83D\uDD12 Security First**: All tool executions happen in secure, sandboxed environments\n",
    "\n",
    "3. **\uD83D\uDCCA Structured Data**: Tools return well-formatted, structured responses that are easy to process\n",
    "\n",
    "4. **\uD83C\uDFE2 Business Ready**: MCP can expose domain-specific business tools and knowledge bases\n",
    "\n",
    "5. **\uD83C\uDF10 Flexible Architecture**: Supports both internal Unity Catalog tools and external Databricks Apps\n",
    "\n",
    "## \uD83D\uDD2E **Next Steps**\n",
    "\n",
    "- **Build Custom Tools**: Create your own MCP servers for specific business needs\n",
    "- **Integrate with AI Agents**: Use these tools in AI agent workflows\n",
    "- **Scale Deployments**: Deploy MCP servers across your organization\n",
    "- **Explore Advanced Features**: Dive deeper into MCP capabilities and integrations\n",
    "\n",
    "## \uD83D\uDCDA **Additional Resources**\n",
    "\n",
    "- [MCP Official Documentation](https://modelcontextprotocol.io/)\n",
    "- [Databricks MCP Integration Guide](https://docs.databricks.com/aws/en/generative-ai/mcp/)\n",
    "- [Unity Catalog Functions](https://docs.databricks.com/en/sql/language-manual/sql-ref-functions-builtin.html)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy building with MCP! \uD83C\uDFAF\uD83D\uDE80**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "MCP SERVERS DEMO - CODE ALONG",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}